{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1eb605fb",
   "metadata": {},
   "source": [
    "\n",
    "# CS412 — Machine Learning — Homework 1  \n",
    "**Topic:** k-Nearest Neighbors on Fashion-MNIST  \n",
    "**Author:** YourName  \n",
    "**Date:** 2025-10-18  \n",
    "\n",
    "> This notebook follows the assignment instructions: train/val/test split, EDA, preprocessing with `StandardScaler`, k-NN hyperparameter tuning across `k` and distance metrics, final evaluation on the test set, error analysis, and timing measurements.  \n",
    "> Make sure to run cells in order. The PDF report should include the requested figures/tables and a shareable link to this notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64907ba6",
   "metadata": {},
   "source": [
    "\n",
    "## 0) Setup & Utilities\n",
    "- Reproducibility (random seeds)  \n",
    "- Imports  \n",
    "- Helper utilities for plotting and analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c403b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Reproducibility\n",
    "import os, random, time\n",
    "import numpy as np\n",
    "\n",
    "SEED = 42\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# Imports\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from typing import Tuple, List\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    classification_report,\n",
    "    confusion_matrix\n",
    ")\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Fashion-MNIST via Keras\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "\n",
    "# Class label names for Fashion-MNIST (official order)\n",
    "CLASS_NAMES = [\n",
    "    \"T-shirt/Top\",  # 0\n",
    "    \"Trouser\",      # 1\n",
    "    \"Pullover\",     # 2\n",
    "    \"Dress\",        # 3\n",
    "    \"Coat\",         # 4\n",
    "    \"Sandal\",       # 5\n",
    "    \"Shirt\",        # 6\n",
    "    \"Sneaker\",      # 7\n",
    "    \"Bag\",          # 8\n",
    "    \"Ankle boot\"    # 9\n",
    "]\n",
    "\n",
    "def plot_class_distribution(y, title=\"Class Distribution\"):\n",
    "    counts = Counter(y.tolist() if hasattr(y, \"tolist\") else y)\n",
    "    xs = list(range(10))\n",
    "    ys = [counts.get(i, 0) for i in xs]\n",
    "    plt.figure()\n",
    "    plt.bar(xs, ys)\n",
    "    plt.xticks(xs, CLASS_NAMES, rotation=45, ha=\"right\")\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Class\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def show_one_sample_per_class(X, y, class_names=CLASS_NAMES):\n",
    "    # expects X as (N, 28, 28)\n",
    "    chosen = {}\n",
    "    for i, label in enumerate(y):\n",
    "        if label not in chosen:\n",
    "            chosen[label] = i\n",
    "        if len(chosen) == len(class_names):\n",
    "            break\n",
    "\n",
    "    cols = len(class_names)\n",
    "    plt.figure(figsize=(cols * 1.6, 1.8))\n",
    "    for idx, cls in enumerate(sorted(chosen.keys())):\n",
    "        plt.subplot(1, cols, idx + 1)\n",
    "        plt.imshow(X[chosen[cls]], cmap=\"gray\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(f\"{class_names[cls]}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def per_class_mean_intensity(X, y, class_names=CLASS_NAMES):\n",
    "    # X shape: (N, 28, 28); returns dict of class -> mean pixel\n",
    "    result = {}\n",
    "    for cls in range(len(class_names)):\n",
    "        cls_pixels = X[y == cls].astype(np.float32)\n",
    "        result[cls] = float(cls_pixels.mean())\n",
    "    return result\n",
    "\n",
    "def plot_validation_curve(results_df):\n",
    "    # One figure; accuracy vs k for each metric\n",
    "    ks = sorted(results_df[\"k\"].unique())\n",
    "    metrics = sorted(results_df[\"metric\"].unique())\n",
    "\n",
    "    plt.figure()\n",
    "    for metric in metrics:\n",
    "        mask = results_df[\"metric\"] == metric\n",
    "        subset = results_df[mask].sort_values(\"k\")\n",
    "        plt.plot(subset[\"k\"], subset[\"val_accuracy\"], marker=\"o\", label=metric)\n",
    "    plt.xlabel(\"k (number of neighbors)\")\n",
    "    plt.ylabel(\"Validation Accuracy\")\n",
    "    plt.title(\"Validation Accuracy vs k for Distance Metrics\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_confusion_matrix(cm, class_names=CLASS_NAMES, title=\"Confusion Matrix\"):\n",
    "    plt.figure(figsize=(6.5, 6))\n",
    "    plt.imshow(cm, interpolation=\"nearest\")\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(class_names))\n",
    "    plt.xticks(tick_marks, class_names, rotation=45, ha=\"right\")\n",
    "    plt.yticks(tick_marks, class_names)\n",
    "    thresh = cm.max() / 2.0 if cm.max() > 0 else 0.0\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            plt.text(j, i, format(cm[i, j], \"d\"),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.ylabel(\"True label\")\n",
    "    plt.xlabel(\"Predicted label\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def top_confused_pairs(cm, top_n=3):\n",
    "    # Return top-N off-diagonal pairs by count\n",
    "    off_diag = []\n",
    "    C = cm.copy()\n",
    "    for i in range(C.shape[0]):\n",
    "        for j in range(C.shape[1]):\n",
    "            if i != j and C[i, j] > 0:\n",
    "                off_diag.append(((i, j), int(C[i, j])))\n",
    "    off_diag.sort(key=lambda x: x[1], reverse=True)\n",
    "    return off_diag[:top_n]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abafd926",
   "metadata": {},
   "source": [
    "\n",
    "## 1) Load Fashion-MNIST and Train/Val/Test Split\n",
    "- Use Keras loader\n",
    "- Split training into train (80%) and validation (20%), with `stratify` and `random_state=42`\n",
    "- Keep the provided test set as-is\n",
    "- Print shapes to verify\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624efc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load data\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "# Split train into train/val (80/20), stratified, reproducible\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_full, y_train_full, test_size=0.2, random_state=42, stratify=y_train_full\n",
    ")\n",
    "\n",
    "print(\"Shapes:\")\n",
    "print(\"  Train:\", X_train.shape, y_train.shape)\n",
    "print(\"  Val:  \", X_val.shape, y_val.shape)\n",
    "print(\"  Test: \", X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c226e186",
   "metadata": {},
   "source": [
    "\n",
    "## 2) Exploratory Data Analysis (Before Preprocessing)\n",
    "- Class distribution (bar chart)  \n",
    "- Global pixel mean/std  \n",
    "- Per-class mean pixel intensity  \n",
    "- One sample image per class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9bfb6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Class distribution on TRAIN set\n",
    "plot_class_distribution(y_train, title=\"Class Distribution (Train)\")\n",
    "\n",
    "# Global pixel statistics (train only)\n",
    "global_mean = float(X_train.astype(np.float32).mean())\n",
    "global_std  = float(X_train.astype(np.float32).std())\n",
    "print(f\"Global pixel mean (train): {global_mean:.4f}\")\n",
    "print(f\"Global pixel std  (train): {global_std:.4f}\")\n",
    "\n",
    "# Per-class mean pixel intensity (train)\n",
    "pc_mean = per_class_mean_intensity(X_train, y_train)\n",
    "for cls_idx, m in pc_mean.items():\n",
    "    print(f\"Mean intensity — {CLASS_NAMES[cls_idx]:<12}: {m:.4f}\")\n",
    "\n",
    "# Show one sample per class (from train)\n",
    "show_one_sample_per_class(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded53ec8",
   "metadata": {},
   "source": [
    "\n",
    "## 3) Preprocessing\n",
    "- Flatten 28×28 → 784  \n",
    "- Standardize features with `StandardScaler` (fit on **train** only)  \n",
    "- Compare mean/std before vs after scaling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63f3928",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Flatten images\n",
    "X_train_flat = X_train.reshape(len(X_train), -1).astype(np.float32)\n",
    "X_val_flat   = X_val.reshape(len(X_val), -1).astype(np.float32)\n",
    "X_test_flat  = X_test.reshape(len(X_test), -1).astype(np.float32)\n",
    "\n",
    "# Before scaling stats (train)\n",
    "pre_mean = float(X_train_flat.mean())\n",
    "pre_std  = float(X_train_flat.std())\n",
    "print(f\"Before scaling — mean: {pre_mean:.4f}, std: {pre_std:.4f}\")\n",
    "\n",
    "# Scale\n",
    "scaler = StandardScaler(with_mean=True, with_std=True)\n",
    "X_train_scaled = scaler.fit_transform(X_train_flat)\n",
    "X_val_scaled   = scaler.transform(X_val_flat)\n",
    "X_test_scaled  = scaler.transform(X_test_flat)\n",
    "\n",
    "# After scaling stats (train)\n",
    "post_mean = float(X_train_scaled.mean())\n",
    "post_std  = float(X_train_scaled.std())\n",
    "print(f\"After scaling  — mean: {post_mean:.4f}, std: {post_std:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81c6777",
   "metadata": {},
   "source": [
    "\n",
    "## 4) k-NN Hyperparameter Tuning\n",
    "- k ∈ {1, 3, 5, 7}  \n",
    "- Distance metric ∈ {`euclidean`, `manhattan`}  \n",
    "- Evaluate on validation set; record accuracy  \n",
    "- Plot validation accuracy vs k for each metric on the same figure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea95553b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "results = []\n",
    "metrics = [\"euclidean\", \"manhattan\"]\n",
    "k_values = [1, 3, 5, 7]\n",
    "\n",
    "for metric in metrics:\n",
    "    for k in k_values:\n",
    "        clf = KNeighborsClassifier(n_neighbors=k, metric=metric, n_jobs=-1)\n",
    "        t0 = time.time()\n",
    "        clf.fit(X_train_scaled, y_train)\n",
    "        fit_time = time.time() - t0\n",
    "\n",
    "        t1 = time.time()\n",
    "        y_val_pred = clf.predict(X_val_scaled)\n",
    "        pred_time = time.time() - t1\n",
    "\n",
    "        acc = accuracy_score(y_val, y_val_pred)\n",
    "        results.append({\n",
    "            \"k\": k,\n",
    "            \"metric\": metric,\n",
    "            \"val_accuracy\": acc,\n",
    "            \"fit_time_s\": fit_time,\n",
    "            \"pred_time_s\": pred_time\n",
    "        })\n",
    "        print(f\"k={k:>2}, metric={metric:<9} | val_acc={acc:.4f} | fit={fit_time:.3f}s | pred={pred_time:.3f}s\")\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "display(results_df.sort_values([\"metric\", \"k\"]).reset_index(drop=True))\n",
    "\n",
    "# Plot validation curve\n",
    "plot_validation_curve(results_df)\n",
    "\n",
    "# Pick best by highest val_accuracy; tie-breaker: smaller k, then euclidean first\n",
    "best = results_df.sort_values(\n",
    "    by=[\"val_accuracy\", \"k\", \"metric\"], ascending=[False, True, True]\n",
    ").iloc[0]\n",
    "best_k = int(best[\"k\"])\n",
    "best_metric = str(best[\"metric\"])\n",
    "print(f\"Best params -> k={best_k}, metric={best_metric}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35aa30cd",
   "metadata": {},
   "source": [
    "\n",
    "## 5) Final Model — Train on (Train + Val), Evaluate on Test\n",
    "- Retrain k-NN with best params on concatenated Train+Val  \n",
    "- Evaluate on Test: Accuracy, Macro Precision/Recall/F1  \n",
    "- Confusion matrix (figure) and discussion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb932d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Concatenate train and val\n",
    "X_trval = np.vstack([X_train_flat, X_val_flat])\n",
    "y_trval = np.concatenate([y_train, y_val])\n",
    "\n",
    "# Scale using scaler fitted on TRAIN (as above, we must refit on Train+Val to avoid leakage?)\n",
    "# To follow the typical pipeline after model selection, we refit the scaler on Train+Val.\n",
    "scaler_final = StandardScaler(with_mean=True, with_std=True)\n",
    "X_trval_scaled = scaler_final.fit_transform(X_trval.astype(np.float32))\n",
    "X_test_scaled_final = scaler_final.transform(X_test_flat.astype(np.float32))\n",
    "\n",
    "# Train with best params\n",
    "clf_final = KNeighborsClassifier(n_neighbors=best_k, metric=best_metric, n_jobs=-1)\n",
    "\n",
    "t0 = time.time()\n",
    "clf_final.fit(X_trval_scaled, y_trval)\n",
    "fit_time_final = time.time() - t0\n",
    "\n",
    "t1 = time.time()\n",
    "y_test_pred = clf_final.predict(X_test_scaled_final)\n",
    "pred_time_final = time.time() - t1\n",
    "\n",
    "# Metrics\n",
    "acc = accuracy_score(y_test, y_test_pred)\n",
    "prec = precision_score(y_test, y_test_pred, average=\"macro\", zero_division=0)\n",
    "rec  = recall_score(y_test, y_test_pred, average=\"macro\", zero_division=0)\n",
    "f1   = f1_score(y_test, y_test_pred, average=\"macro\", zero_division=0)\n",
    "\n",
    "print(f\"Test Accuracy: {acc:.4f}\")\n",
    "print(f\"Macro Precision: {prec:.4f}\")\n",
    "print(f\"Macro Recall:    {rec:.4f}\")\n",
    "print(f\"Macro F1-score:  {f1:.4f}\")\n",
    "print(f\"Final fit time (s):   {fit_time_final:.3f}\")\n",
    "print(f\"Final predict time(s): {pred_time_final:.3f}\")\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "plot_confusion_matrix(cm, class_names=CLASS_NAMES, title=\"Confusion Matrix (Test)\")\n",
    "\n",
    "# Classification report (printed)\n",
    "print(\"\\nClassification Report (Test):\\n\")\n",
    "print(classification_report(y_test, y_test_pred, target_names=CLASS_NAMES, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d15d102",
   "metadata": {},
   "source": [
    "\n",
    "## 6) Error Analysis\n",
    "- Identify top-3 most confused class pairs (off-diagonal highest counts)  \n",
    "- For each pair, display 5 random misclassified examples (pred vs true)  \n",
    "- Short discussion: possible reasons (visual similarity, texture, silhouette)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16aba46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Find top-3 confused pairs\n",
    "pairs = top_confused_pairs(cm, top_n=3)\n",
    "print(\"Top confused pairs (true -> pred) with counts:\")\n",
    "for (i, j), c in pairs:\n",
    "    print(f\"  {CLASS_NAMES[i]} -> {CLASS_NAMES[j]}: {c}\")\n",
    "\n",
    "# Gather indices of misclassifications for each pair and visualize 5 examples\n",
    "rng = np.random.default_rng(SEED)\n",
    "\n",
    "for (true_c, pred_c), count in pairs:\n",
    "    # find indices in test set where y_true=true_c and y_pred=pred_c\n",
    "    idxs = np.where((y_test == true_c) & (y_test_pred == pred_c))[0]\n",
    "    if len(idxs) == 0:\n",
    "        continue\n",
    "    chosen = rng.choice(idxs, size=min(5, len(idxs)), replace=False)\n",
    "\n",
    "    plt.figure(figsize=(10, 2.2))\n",
    "    for k, idx in enumerate(chosen, start=1):\n",
    "        plt.subplot(1, min(5, len(chosen)), k)\n",
    "        plt.imshow(X_test[idx], cmap=\"gray\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(f\"Pred: {CLASS_NAMES[pred_c]}\\nTrue: {CLASS_NAMES[true_c]}\")\n",
    "    plt.suptitle(f\"Misclassified — {CLASS_NAMES[true_c]} → {CLASS_NAMES[pred_c]} (n={len(idxs)})\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"Discussion ideas:\")\n",
    "print(\"- Classes with similar silhouettes (e.g., T-shirt/Top vs Shirt, Pullover vs Coat).\")\n",
    "print(\"- Texture & material cues are weak in 28×28 grayscale images.\")\n",
    "print(\"- k and metric choices may emphasize local neighborhoods that blur class boundaries.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e16074a",
   "metadata": {},
   "source": [
    "\n",
    "## 7) Computational Analysis — k-NN as a Lazy Learner\n",
    "- Report training (fit) and prediction times  \n",
    "- Briefly explain why k-NN is a **lazy learner** (no parametric model is trained; the “training” phase is just storing the data; prediction involves distance computations to many stored instances)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcaa7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(f\"Final model fit time (s):   {fit_time_final:.3f}\")\n",
    "print(f\"Final model predict time(s): {pred_time_final:.3f}\")\n",
    "print(\"k-NN is a lazy learner because it does not build an explicit parametric model during training;\")\n",
    "print(\"instead, it stores the training data and defers most computation to prediction time,\")\n",
    "print(\"where distances to many points are computed to find nearest neighbors.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0b438a",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### Deliverables & Notes\n",
    "- Ensure your PDF report includes:\n",
    "  - Methodology and EDA summaries\n",
    "  - Validation curve (accuracy vs k for each metric)\n",
    "  - Test results (Accuracy, Macro P/R/F1) and confusion matrix figure + commentary\n",
    "  - Error analysis (top confused pairs + examples + discussion)\n",
    "  - Timing results and k-NN “lazy learner” explanation\n",
    "  - A shareable link to this notebook at the top\n",
    "\n",
    "- Rename this file to **`CS412-HW1-YourName.ipynb`** before submission.\n",
    "\n",
    "Good luck!\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
